{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8e451a-e202-4318-a10e-223825bed8d4",
   "metadata": {},
   "source": [
    "## 3. Multiple input/output training\n",
    "Goal: Enhance the baseline emulator by incorporating more outputs\n",
    "- Phase 0:\n",
    "  <br> - **in:** T_surf, SST, SIC, land_mask, Z500, T850, SLP\n",
    "  <br> - **out:** T_surf\n",
    "- Phase 1:\n",
    "  <br> - **in:** + T2m\n",
    "  <br> - **out:** + T2m\n",
    "- Phase 2:\n",
    "  <br> - **in:** + U10 + V10\n",
    "  <br> - **out:** + U10 + V10\n",
    "- Phase 3:\n",
    "  <br> - **in:** + U500 + V500\n",
    "  <br> - **out:** + U500 + V500\n",
    "- Phase 4:\n",
    "  <br> - **in:** + Q850 + Q500\n",
    "  <br> - **out:** + Q850 + Q500\n",
    "- Phase 5:\n",
    "  <br> - **out:** Total precipitation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f131aae6-e147-469f-bffa-3354f5be5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import process_variable, get_indices\n",
    "from architectures.cnn_baseline import CNN2D_Baseline, set_seed\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "variables = [{'var_name': \"t_ref\",\n",
    "              \"file_name\": \"DATA/atmos.192101-201012.t_ref.nc\",\n",
    "              \"add_spatial\": True,\n",
    "              \"lag_data_set\": True,\n",
    "              \"is_static\": False,\n",
    "              \"standardize\": True,\n",
    "              \"is_output\": True},\n",
    "             {'var_name': \"t_surf\",\n",
    "              \"file_name\": \"DATA/atmos.192101-201012.t_surf.nc\",\n",
    "              \"add_spatial\": False,\n",
    "              \"lag_data_set\": True,\n",
    "              \"is_static\": False,\n",
    "              \"standardize\": True,\n",
    "              \"is_output\": True,}\n",
    "]\n",
    "\n",
    "num_epochs = 50\n",
    "Models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e0afa2-cd90-493b-8693-19988023b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_ref - INFO - Working on var: t_ref from DATA/atmos.192101-201012.t_ref.nc\n",
      "t_ref - INFO - X_train_scaled : (861, 7, 90, 90)\n",
      "t_ref - INFO - X_test_scaled : (213, 7, 90, 90)\n",
      "t_ref - INFO - y_train_scaled : (861, 1, 90, 90)\n",
      "t_ref - INFO - y_test_scaled : (213, 1, 90, 90)\n",
      "t_ref - INFO - y_train : (861, 90, 90)\n",
      "t_ref - INFO - y_test : (213, 90, 90)\n",
      "t_surf - INFO - Working on var: t_surf from DATA/atmos.192101-201012.t_surf.nc\n",
      "t_surf - INFO - X_train_scaled : (861, 3, 90, 90)\n",
      "t_surf - INFO - X_test_scaled : (213, 3, 90, 90)\n",
      "t_surf - INFO - y_train_scaled : (861, 1, 90, 90)\n",
      "t_surf - INFO - y_test_scaled : (213, 1, 90, 90)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "var_data = []\n",
    "for variable in variables:\n",
    "    var_name = variable['var_name']\n",
    "\n",
    "    file_name = variable['file_name']\n",
    "    add_spatial = variable['add_spatial']\n",
    "    lag_data_set = variable['lag_data_set']\n",
    "    is_static = variable['is_static']\n",
    "    standardize = variable['standardize']\n",
    "    fill_value_method = variable.get('fill_value_method')\n",
    "    is_output = variable.get('is_output', False)\n",
    "\n",
    "    var_data.append(process_variable(file_name, var_name, lag_data_set,\n",
    "                                     add_spatial, is_static, standardize,\n",
    "                                     fill_value_method=fill_value_method,\n",
    "                                     isOutput=is_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98ea5f-5ee1-4889-ba64-4094b1ed3090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_ref is an output!\n",
      "t_surf is an output!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - X_train_scaled : (861, 10, 90, 90)\n",
      "root - INFO - X_test_scaled : (213, 10, 90, 90)\n",
      "root - INFO - y_train_scaled : (861, 2, 90, 90)\n",
      "root - INFO - y_test_scaled : (213, 2, 90, 90)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_test_scaleds = []\n",
    "x_train_scaleds = []\n",
    "y_test_scaleds = []\n",
    "y_train_scaleds = []\n",
    "\n",
    "end = 0\n",
    "for variable in var_data:\n",
    "    if variable['varname'] == \"t_ref\":\n",
    "        time_test = variable['time']\n",
    "        nsamples_train = variable['X_train_scaled'].shape[0]\n",
    "        nsamples_test = variable['X_test_scaled'].shape[0]\n",
    "\n",
    "    start = end\n",
    "    if variable['varname'] == \"wet\":\n",
    "        end = start + 1\n",
    "        static_train = np.broadcast_to(\n",
    "            variable['X_train_scaled'],\n",
    "            (nsamples_train,) + variable['X_train_scaled'].shape[1:]\n",
    "        )\n",
    "        static_test = np.broadcast_to(\n",
    "            variable['X_test_scaled'],\n",
    "            (nsamples_test,) + variable['X_test_scaled'].shape[1:]\n",
    "        )\n",
    "\n",
    "        x_train_scaleds.append(static_train)\n",
    "        x_test_scaleds.append(static_test)\n",
    "    else:\n",
    "        end = start + variable['X_test_scaled'].shape[1]\n",
    "        x_test_scaleds.append(variable['X_test_scaled'])\n",
    "        x_train_scaleds.append(variable['X_train_scaled'])\n",
    "\n",
    "    variable['start'] = start\n",
    "    variable['end'] = end\n",
    "\n",
    "    is_output = variable.get('is_output', False)\n",
    "    if is_output:\n",
    "        print(f\"{variable['varname']} is an output!\")\n",
    "        y_test_scaleds.append(variable['y_test_scaled'])\n",
    "        y_train_scaleds.append(variable['y_train_scaled'])\n",
    "        \n",
    "X_train_scaled = np.concatenate(x_train_scaleds, axis=1)\n",
    "X_test_scaled = np.concatenate(x_test_scaleds, axis=1)\n",
    "y_train_scaled = np.concatenate(y_train_scaleds, axis=1)\n",
    "y_test_scaled = np.concatenate(y_test_scaleds, axis=1)\n",
    "\n",
    "logging.info(f\"X_train_scaled : {X_train_scaled.shape}\")\n",
    "logging.info(f\"X_test_scaled : {X_test_scaled.shape}\")\n",
    "logging.info(f\"y_train_scaled : {y_train_scaled.shape}\")\n",
    "logging.info(f\"y_test_scaled : {y_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89eb40-33ab-4037-8c2e-86f298c33e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - X_train_scaled : (861, 10, 90, 90)\n",
      "root - INFO - X_test_scaled : (213, 10, 90, 90)\n",
      "root - INFO - y_train_scaled : (861, 2, 90, 90)\n",
      "root - INFO - y_test_scaled : (213, 2, 90, 90)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "Sequential(\n",
      "  (0): Conv2d(10, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU()\n",
      "  (9): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): ReLU()\n",
      "  (15): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Epoch 0/50, Training Loss: 56405.939460 Validation Loss: 56118.656250\n",
      "Epoch 10/50, Training Loss: 33768.948089 Validation Loss: 33096.984375\n"
     ]
    }
   ],
   "source": [
    "variable_set = [\"t_ref\", \"t_surf\"]\n",
    "indices = get_indices(var_data, variable_set)\n",
    "X_train_scaled_prime = np.concatenate([X_train_scaled[:, start:end, :, :] for start, end in indices], axis=1)\n",
    "X_test_scaled_prime = np.concatenate([X_test_scaled[:, start:end, :, :] for start, end in indices], axis=1)\n",
    "logging.info(f\"X_train_scaled : {X_train_scaled_prime.shape}\")\n",
    "logging.info(f\"X_test_scaled : {X_test_scaled_prime.shape}\")\n",
    "logging.info(f\"y_train_scaled : {y_train_scaled.shape}\")\n",
    "logging.info(f\"y_test_scaled : {y_test_scaled.shape}\")\n",
    "\n",
    "set_seed()\n",
    "out_var_maps = [{'var_name': 't_ref', \n",
    "                 'out_channel': 0,\n",
    "                 'weight': 1,\n",
    "                 'loss': 0},\n",
    "                {'var_name': 't_surf',\n",
    "                 'out_channel': 1,\n",
    "                 'weight': 1,\n",
    "                 'loss': 0}\n",
    "                ]\n",
    "step1 = CNN2D_Baseline(in_channels=X_train_scaled_prime.shape[1], case=2, label=\"deletedeletedelete\",\n",
    "                       out_channels=2, out_var_maps=out_var_maps)\n",
    "train_loader, test_loader = step1.create_data_loaders(X_train_scaled_prime, y_train_scaled, X_test_scaled_prime, y_test_scaled)\n",
    "step1.train_model(train_loader, test_loader, num_epochs=num_epochs)\n",
    "\n",
    "#step1.get_rmse(var_data[0]['tas_data'], X_test_scaled_prime, y_test_scaled, ranges=(17.449455, 1665.3541))\n",
    "# RMSE = step1.get_global_rmse_over_time(var_data[0]['tas_data'], X_test_scaled_prime, y_test_scaled)\n",
    "# Models.append({'Model Name': 'Baseline', 'Trained Model': step1, 'RMSE': RMSE, 'Slope': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ad143-2b2d-49d2-adf7-c4c9fa6ed965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
